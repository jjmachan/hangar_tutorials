{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hangar Tutorial (1/2): Adding your data to Hangar\n",
    "#### A step by step guide to setting up a hangar repo and adding your data to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This an accompanying notebook with the tutorial blog on [Hangar](hanga). In this notebook we will go through how you can add your data to hangar for versioning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hangar\n",
    "from hangar import Repository\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import gzip\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.5.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hangar.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the MNIST dataset for this tutorial. Download MNIST from [here](https://github.com/mnielsen/neural-networks-and-deep-learning/raw/master/data/mnist.pkl.gz) and save it to a known path. A copy is given in this github repo also.\n",
    "\n",
    "## Initialize the Repo\n",
    "\n",
    "As explained in the blog each dataset is contained in a **Repository**. You initialize a repo with the *init()* method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hangar Repo initialized at: /home/jjmachan/jjmachan/hangar_tutorial/.hangar\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Hangar Repository               \n",
       "    Repository Path  : /home/jjmachan/jjmachan/hangar_tutorial               \n",
       "    Writer-Lock Free : True\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo = Repository('./')\n",
    "repo.init(user_name='jjmachan', user_email='jjmachan@g.com', remove_old=True)\n",
    "repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*remote* is used to access remote copies of the Hangar repository that you may have or create. Once really cool feature in Hangar is that it allows partial downloads from Remote repositories. This is really handy when working with huge datasets on your dev envs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list all remote repos\n",
    "repo.remote.list_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hangar WriterCheckout                \n",
       "    Writer       : True                \n",
       "    Base Branch  : master                \n",
       "    Num Columns  : 6\n"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write enabled Checkout to write data to repo\n",
    "co = repo.checkout(write=True)\n",
    "co"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: You can only have on write enabled checkout, so if you don't close your checkout before creating new onces it will show errors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "Cannot acquire the writer lock. Only one instance of a writer checkout can be active at a time. If the last checkout of this repository did not properly close, or a crash occurred, the lock must be manually freed before another writer can be instantiated.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-ab4435a10f3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mco2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/jjmachan/hangar-py/src/hangar/repository.py\u001b[0m in \u001b[0;36mcheckout\u001b[0;34m(self, write, branch, commit)\u001b[0m\n\u001b[1;32m    280\u001b[0m                     \u001b[0mstageenv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstageenv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m                     \u001b[0mbranchenv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbranchenv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m                     stagehashenv=self._env.stagehashenv)\n\u001b[0m\u001b[1;32m    283\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mco\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mwrite\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jjmachan/hangar-py/src/hangar/checkout.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, repo_pth, branch_name, hashenv, refenv, stageenv, branchenv, stagehashenv, mode)\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_columns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mColumns\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_differ\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mWriterUserDiff\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m         \u001b[0matexit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jjmachan/hangar-py/src/hangar/checkout.py\u001b[0m in \u001b[0;36m_setup\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mbase\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mcheckout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \"\"\"\n\u001b[0;32m--> 493\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_verify_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0mcurrent_head\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mheads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_staging_branch_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_branchenv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m         currentDiff = WriterUserDiff(stageenv=self._stageenv,\n",
      "\u001b[0;32m~/jjmachan/hangar-py/src/hangar/checkout.py\u001b[0m in \u001b[0;36m_verify_alive\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0msuppress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_differ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jjmachan/hangar-py/src/hangar/checkout.py\u001b[0m in \u001b[0;36m_verify_alive\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m             \u001b[0mheads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire_writer_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_branchenv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_writer_lock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0msuppress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jjmachan/hangar-py/src/hangar/records/heads.py\u001b[0m in \u001b[0;36macquire_writer_lock\u001b[0;34m(branchenv, writer_uuid)\u001b[0m\n\u001b[1;32m    121\u001b[0m                   \u001b[0;34m'not properly close, or a crash occurred, the lock must be manually freed '\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                   \u001b[0;34m'before another writer can be instantiated.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mPermissionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mTxnRegister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommit_writer_txn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbranchenv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPermissionError\u001b[0m: Cannot acquire the writer lock. Only one instance of a writer checkout can be active at a time. If the last checkout of this repository did not properly close, or a crash occurred, the lock must be manually freed before another writer can be instantiated."
     ]
    }
   ],
   "source": [
    "co2 = repo.checkout(write=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columns\n",
    "These are the structures that are used to store the data as numpy arrays. both numeric and string data can be stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hangar Columns                \n",
       "    Writeable         : True                \n",
       "    Number of Columns : 0                \n",
       "    Column Names / Partial Remote References:                \n",
       "      - "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "with gzip.open('./mnist.pkl.gz', 'rb') as f:\n",
    "    train_set, valid_set, test_set = pickle.load(f, encoding='bytes')\n",
    "\n",
    "# sample image and label for creating columns\n",
    "sample_trimg = train_set[0][0]\n",
    "sample_trlabel = np.array([train_set[1][0]])\n",
    "\n",
    "# training images\n",
    "trimgs = train_set[0]\n",
    "trlabels = train_set[1]\n",
    "\n",
    "# add it to a list\n",
    "data = [train_set, valid_set, test_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((784,), dtype('float32'))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_trimg.shape, sample_trimg.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets create columns using the *add_ndarray_column()*. It takes a *name* and the *shape* and *dtype* which hangar can infer if you provide a sample data using the *prototype=* argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hangar FlatSampleWriter                 \n",
       "    Column Name              : mnist_training_labels                \n",
       "    Writeable                : True                \n",
       "    Column Type              : ndarray                \n",
       "    Column Layout            : flat                \n",
       "    Schema Type              : fixed_shape                \n",
       "    DType                    : int64                \n",
       "    Shape                    : (1,)                \n",
       "    Number of Samples        : 0                \n",
       "    Partial Remote Data Refs : False\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "co.add_ndarray_column(name='mnist_training_images', prototype=sample_trimg)\n",
    "co.add_ndarray_column(name='mnist_training_labels', prototype=sample_trlabel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hangar FlatSampleWriter                 \n",
       "    Column Name              : mnist_test_labels                \n",
       "    Writeable                : True                \n",
       "    Column Type              : ndarray                \n",
       "    Column Layout            : flat                \n",
       "    Schema Type              : fixed_shape                \n",
       "    DType                    : int64                \n",
       "    Shape                    : (1,)                \n",
       "    Number of Samples        : 0                \n",
       "    Partial Remote Data Refs : False\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Val\n",
    "co.add_ndarray_column(name='mnist_validation_images', prototype=sample_trimg)\n",
    "co.add_ndarray_column(name='mnist_validation_labels', prototype=sample_trlabel)\n",
    "\n",
    "# Test\n",
    "co.add_ndarray_column(name='mnist_test_images', prototype=sample_trimg)\n",
    "co.add_ndarray_column(name='mnist_test_labels', prototype=sample_trlabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FlatSampleWriter(repo_pth=/home/jjmachan/jjmachan/hangar_tutorial/.hangar, aset_name=mnist_training_images, ['column_layout=flat, ', 'column_type=ndarray, ', 'schema_hasher_tcode=1, ', 'data_hasher_tcode=0, ', 'schema_type=fixed_shape, ', 'shape=(784,), ', 'dtype=float32, ', 'backend=00, ', \"backend_options={'complib': 'blosc:lz4hc', 'complevel': 5, 'shuffle': 'byte'}, \"], mode=a) FlatSampleWriter(repo_pth=/home/jjmachan/jjmachan/hangar_tutorial/.hangar, aset_name=mnist_training_labels, ['column_layout=flat, ', 'column_type=ndarray, ', 'schema_hasher_tcode=1, ', 'data_hasher_tcode=0, ', 'schema_type=fixed_shape, ', 'shape=(1,), ', 'dtype=int64, ', 'backend=10, ', 'backend_options={}, '], mode=a) \n",
      "\n",
      "FlatSampleWriter(repo_pth=/home/jjmachan/jjmachan/hangar_tutorial/.hangar, aset_name=mnist_validation_images, ['column_layout=flat, ', 'column_type=ndarray, ', 'schema_hasher_tcode=1, ', 'data_hasher_tcode=0, ', 'schema_type=fixed_shape, ', 'shape=(784,), ', 'dtype=float32, ', 'backend=00, ', \"backend_options={'complib': 'blosc:lz4hc', 'complevel': 5, 'shuffle': 'byte'}, \"], mode=a) FlatSampleWriter(repo_pth=/home/jjmachan/jjmachan/hangar_tutorial/.hangar, aset_name=mnist_validation_labels, ['column_layout=flat, ', 'column_type=ndarray, ', 'schema_hasher_tcode=1, ', 'data_hasher_tcode=0, ', 'schema_type=fixed_shape, ', 'shape=(1,), ', 'dtype=int64, ', 'backend=10, ', 'backend_options={}, '], mode=a) \n",
      "\n",
      "FlatSampleWriter(repo_pth=/home/jjmachan/jjmachan/hangar_tutorial/.hangar, aset_name=mnist_test_images, ['column_layout=flat, ', 'column_type=ndarray, ', 'schema_hasher_tcode=1, ', 'data_hasher_tcode=0, ', 'schema_type=fixed_shape, ', 'shape=(784,), ', 'dtype=float32, ', 'backend=00, ', \"backend_options={'complib': 'blosc:lz4hc', 'complevel': 5, 'shuffle': 'byte'}, \"], mode=a) FlatSampleWriter(repo_pth=/home/jjmachan/jjmachan/hangar_tutorial/.hangar, aset_name=mnist_test_labels, ['column_layout=flat, ', 'column_type=ndarray, ', 'schema_hasher_tcode=1, ', 'data_hasher_tcode=0, ', 'schema_type=fixed_shape, ', 'shape=(1,), ', 'dtype=int64, ', 'backend=10, ', 'backend_options={}, '], mode=a) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# list all the columns created\n",
    "column_list = [('train', 'mnist_training_images', 'mnist_training_labels'), ('val', 'mnist_validation_images', 'mnist_validation_labels'), ('test', 'mnist_test_images', 'mnist_test_labels')]\n",
    "for _, imgs, labels in column_list:\n",
    "    print(co.columns[imgs], co.columns[labels], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding train data\n",
      "Adding val data\n",
      "Adding test data\n"
     ]
    }
   ],
   "source": [
    "# actually adding data\n",
    "for i, (split, imgs, labels) in enumerate(column_list):\n",
    "    print(f'Adding {split} data')\n",
    "    img_col , label_col = co.columns[imgs], co.columns[labels]\n",
    "    \n",
    "    # using the context managers\n",
    "    # skip them out to see the time differences.\n",
    "    with img_col, label_col:\n",
    "        for idx, image in enumerate(data[i][0]):\n",
    "            \n",
    "            # column[idx] invokes the __setter__ function and \n",
    "            # adds the data assigned with the corresponding idx(index)\n",
    "            # to hangar\n",
    "            img_col[idx] = image\n",
    "            label_col[idx] = np.array([data[i][1][idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hangar FlatSampleWriter                 \n",
       "    Column Name              : mnist_training_images                \n",
       "    Writeable                : True                \n",
       "    Column Type              : ndarray                \n",
       "    Column Layout            : flat                \n",
       "    Schema Type              : fixed_shape                \n",
       "    DType                    : float32                \n",
       "    Shape                    : (784,)                \n",
       "    Number of Samples        : 50000                \n",
       "    Partial Remote Data Refs : False\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Details of the new column\n",
    "# Note the number of samples has increased to 5000\n",
    "co.columns['mnist_training_images']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a=39a36c4fa931e82172f03edd8ccae56bf086129b'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the changes from this checkout to disk\n",
    "co.commit('added all the mnist datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* a=39a36c4fa931e82172f03edd8ccae56bf086129b (\u001b[1;31mmaster\u001b[m) : added all the mnist datasets\n"
     ]
    }
   ],
   "source": [
    "# see the commits using the logs\n",
    "repo.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of Contents Contained in Data Repository \n",
      " \n",
      "================== \n",
      "| Repository Info \n",
      "|----------------- \n",
      "|  Base Directory: /home/jjmachan/jjmachan/hangar_tutorial \n",
      "|  Disk Usage: 105.88 MB \n",
      " \n",
      "=================== \n",
      "| Commit Details \n",
      "------------------- \n",
      "|  Commit: a=39a36c4fa931e82172f03edd8ccae56bf086129b \n",
      "|  Created: Fri May  1 18:23:19 2020 \n",
      "|  By: jjmachan \n",
      "|  Email: jjmachan@g.com \n",
      "|  Message: added all the mnist datasets \n",
      " \n",
      "================== \n",
      "| DataSets \n",
      "|----------------- \n",
      "|  Number of Named Columns: 6 \n",
      "|\n",
      "|  * Column Name: ColumnSchemaKey(column=\"mnist_test_images\", layout=\"flat\") \n",
      "|    Num Data Pieces: 10000 \n",
      "|    Details: \n",
      "|    - column_layout: flat \n",
      "|    - column_type: ndarray \n",
      "|    - schema_hasher_tcode: 1 \n",
      "|    - data_hasher_tcode: 0 \n",
      "|    - schema_type: fixed_shape \n",
      "|    - shape: (784,) \n",
      "|    - dtype: float32 \n",
      "|    - backend: 00 \n",
      "|    - backend_options: {'complib': 'blosc:lz4hc', 'complevel': 5, 'shuffle': 'byte'} \n",
      "|\n",
      "|  * Column Name: ColumnSchemaKey(column=\"mnist_test_labels\", layout=\"flat\") \n",
      "|    Num Data Pieces: 10000 \n",
      "|    Details: \n",
      "|    - column_layout: flat \n",
      "|    - column_type: ndarray \n",
      "|    - schema_hasher_tcode: 1 \n",
      "|    - data_hasher_tcode: 0 \n",
      "|    - schema_type: fixed_shape \n",
      "|    - shape: (1,) \n",
      "|    - dtype: int64 \n",
      "|    - backend: 10 \n",
      "|    - backend_options: {} \n",
      "|\n",
      "|  * Column Name: ColumnSchemaKey(column=\"mnist_training_images\", layout=\"flat\") \n",
      "|    Num Data Pieces: 50000 \n",
      "|    Details: \n",
      "|    - column_layout: flat \n",
      "|    - column_type: ndarray \n",
      "|    - schema_hasher_tcode: 1 \n",
      "|    - data_hasher_tcode: 0 \n",
      "|    - schema_type: fixed_shape \n",
      "|    - shape: (784,) \n",
      "|    - dtype: float32 \n",
      "|    - backend: 00 \n",
      "|    - backend_options: {'complib': 'blosc:lz4hc', 'complevel': 5, 'shuffle': 'byte'} \n",
      "|\n",
      "|  * Column Name: ColumnSchemaKey(column=\"mnist_training_labels\", layout=\"flat\") \n",
      "|    Num Data Pieces: 50000 \n",
      "|    Details: \n",
      "|    - column_layout: flat \n",
      "|    - column_type: ndarray \n",
      "|    - schema_hasher_tcode: 1 \n",
      "|    - data_hasher_tcode: 0 \n",
      "|    - schema_type: fixed_shape \n",
      "|    - shape: (1,) \n",
      "|    - dtype: int64 \n",
      "|    - backend: 10 \n",
      "|    - backend_options: {} \n",
      "|\n",
      "|  * Column Name: ColumnSchemaKey(column=\"mnist_validation_images\", layout=\"flat\") \n",
      "|    Num Data Pieces: 10000 \n",
      "|    Details: \n",
      "|    - column_layout: flat \n",
      "|    - column_type: ndarray \n",
      "|    - schema_hasher_tcode: 1 \n",
      "|    - data_hasher_tcode: 0 \n",
      "|    - schema_type: fixed_shape \n",
      "|    - shape: (784,) \n",
      "|    - dtype: float32 \n",
      "|    - backend: 00 \n",
      "|    - backend_options: {'complib': 'blosc:lz4hc', 'complevel': 5, 'shuffle': 'byte'} \n",
      "|\n",
      "|  * Column Name: ColumnSchemaKey(column=\"mnist_validation_labels\", layout=\"flat\") \n",
      "|    Num Data Pieces: 10000 \n",
      "|    Details: \n",
      "|    - column_layout: flat \n",
      "|    - column_type: ndarray \n",
      "|    - schema_hasher_tcode: 1 \n",
      "|    - data_hasher_tcode: 0 \n",
      "|    - schema_type: fixed_shape \n",
      "|    - shape: (1,) \n",
      "|    - dtype: int64 \n",
      "|    - backend: 10 \n",
      "|    - backend_options: {} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# You can see the whole summary of the repo using this function.\n",
    "repo.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: \n",
    "always remember to close the checkpoints after you have written the data and commited it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "co.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
